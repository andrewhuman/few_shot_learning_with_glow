{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "from utils import *\n",
    "import collections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glow import thops\n",
    "from glow import modules\n",
    "from glow import models\n",
    "from glow.config import JsonConfig\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# negative\n",
    "path_total = '/home/hyshuai/workspace/dataset/images_background'\n",
    "\n",
    "dataset_negative = []\n",
    "for path_p in os.listdir(path_total):\n",
    "        path_p_join = os.path.join(path_total,path_p)\n",
    "        for path_c in os.listdir(path_p_join):\n",
    "            path_real = os.path.join(path_p_join,path_c)\n",
    "            class_name = path_real\n",
    "            # image_paths = get_image_paths(path_real)\n",
    "            images = get_images_frompath(path_real)\n",
    "            print(class_name,\" : \",len(images))\n",
    "            dataset_negative.append(ImageObject(class_name,images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# positive\n",
    "\n",
    "path_positive_total = '/home/hyshuai/workspace/dataset/images_evaluation'\n",
    "class_name_list = []\n",
    "for path_p in os.listdir(path_positive_total):\n",
    "    path_p_join = os.path.join(path_positive_total,path_p)\n",
    "    for path_c in os.listdir(path_p_join):\n",
    "        path_real = os.path.join(path_p_join,path_c)\n",
    "        class_name = path_real\n",
    "        class_name_list.append(str(class_name))\n",
    "\n",
    "# class_name = np.array(class_name)\n",
    "# print(class_name_list)\n",
    "np.random.seed(66) # 切换类试下\n",
    "shufindex = np.random.permutation(len(class_name_list))\n",
    "# print(shufindex)\n",
    "class_positive = np.array(class_name_list)[shufindex][:20] #取5个类做测试 5-way\n",
    "print(class_positive)\n",
    "\n",
    "dataset_train_positive =[]\n",
    "dataset_test_positive = []\n",
    "for class_path in class_positive :\n",
    "    images = get_images_frompath_random(class_path) # 固定随机抽样是否有问题\n",
    "    print(class_path, \" : \", len(images))\n",
    "    dataset_train_positive.append(ImageObject(class_path, images[:1])) # 1-shot\n",
    "    dataset_test_positive.append(ImageObject(class_path, images[1:]))\n",
    "\n",
    "\n",
    "\n",
    "print(len(dataset_train_positive[2].imgs))\n",
    "print(len(dataset_test_positive[2].imgs))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# label:\n",
    "\n",
    "class_total_num = len(dataset_negative) + len(dataset_train_positive)\n",
    "print(\"class_total = \",class_total_num)\n",
    "np.random.seed(66) \n",
    "shufindex = np.random.permutation(class_total_num)\n",
    "for index, value in enumerate(dataset_negative):\n",
    "    value.label = shufindex[index]\n",
    "    print(value.name,  value.label)\n",
    "\n",
    "for index, value in enumerate(dataset_train_positive):\n",
    "    value.label = shufindex[index+len(dataset_negative)]\n",
    "    dataset_test_positive[index].label = shufindex[index+len(dataset_negative)]\n",
    "    print(value.name, value.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_class_index = [122,51,631,828,20]\n",
    "test_class_index = [data.label for data in dataset_train_positive]\n",
    "print(test_class_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(dataset_test_positive[0].name)\n",
    "# np.random.shuffle(dataset_test_positive)\n",
    "# print(dataset_test_positive[0].name)\n",
    "# imgs_show(np.squeeze( dataset_test_positive[0].imgs),1,5) \n",
    "# imgs_show(np.squeeze(dataset_negative[1].imgs),4,5)\n",
    "class_total_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(dataset_negative[0].imgs[2].shape)\n",
    "# # print(im[15])\n",
    "# # print(im.shape)\n",
    "# print(dataset_negative[0].imgs[0].shape)\n",
    "x = [data.imgs for data in dataset_train_positive] \n",
    "print(x[0].shape)\n",
    "img_show(np.squeeze(x[0]))\n",
    "img_show(np.squeeze(x[1]))\n",
    "img_show(np.squeeze(x[2]))\n",
    "img_show(np.squeeze(x[3]))\n",
    "img_show(np.squeeze(x[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_next_perfect(dataset_train_positive,dataset_negative,p_size,n_size):\n",
    "    \"\"\"\n",
    "    final batch_size = p_size + n_size * 2\n",
    "    every dataset_negative should have same imgs leng\n",
    "    \"\"\"\n",
    "    #shuffle\n",
    "    np.random.shuffle(dataset_train_positive)\n",
    "    np.random.shuffle(dataset_negative)\n",
    "    for data in dataset_negative:\n",
    "        np.random.shuffle(data.imgs)\n",
    "    for data in dataset_train_positive:\n",
    "        np.random.shuffle(data.imgs)\n",
    "    \n",
    "    \n",
    "    batch_negative = n_size * 2\n",
    "#     print('batch_negative ',batch_negative)\n",
    "    len_n_class = len(dataset_negative)\n",
    "#     print('len_n_class ',len_n_class)\n",
    "    len_p_class = len(dataset_train_positive)\n",
    "#     print('len_p_class ',len_p_class)\n",
    "    len_n_imgs = len(dataset_negative[0].imgs)\n",
    "#     print('len_n_imgs ',len_n_imgs)\n",
    "    len_p_imgs = len(dataset_train_positive[0].imgs)\n",
    "    \n",
    "    negative_number = 0\n",
    "    \n",
    "    \n",
    "#     shuffindex = np.random.permutation(len_n)\n",
    "# #     print(shuffindex)\n",
    "#     np.random.shuffle(dataset_train_positive)\n",
    "#     np.random.shuffle(dataset_negative)\n",
    "    \n",
    "    for data in dataset_negative:\n",
    "        negative_number += len(data.imgs)\n",
    "#         np.random.shuffle(data.imgs)\n",
    "#     print('negative_number ',negative_number)\n",
    "    batch_total = negative_number  // batch_negative\n",
    "#     print('batch_total ',batch_total)\n",
    "    i_n_class = 0\n",
    "    i_n_img = 0\n",
    "    i_p_class = 0\n",
    "    i_p_img = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    for b in range(batch_total):\n",
    "        train_x =[]\n",
    "        train_y = []\n",
    "        create_negative_imgs = 0\n",
    "        while create_negative_imgs <= (batch_total * batch_negative) and create_negative_imgs < batch_negative:\n",
    "            \n",
    "            # while #如果一次循环没够，需要再次循环\n",
    "            if i_n_class >= len_n_class:\n",
    "                    i_n_class = 0\n",
    "                    i_n_img +=1\n",
    "                    if (i_n_img+1) *2 >len_n_imgs:\n",
    "                        i_n_img = 0\n",
    "#                     print('if i_n_class >= len_n_class i_n_class ',i_n_class)\n",
    "#                     print('if i_n_class >= len_n_class i_n_img ',i_n_img)\n",
    "            \n",
    "            for i in range(i_n_class,len_n_class):\n",
    "                    \n",
    "#                 print('for i in range(i_n_class i_n_class ',i_n_class)\n",
    "#                 print('for i in range(i_n_class i_n_img ',i_n_img)\n",
    "                train_x += dataset_negative[i_n_class].imgs[i_n_img * 2 : (i_n_img+1) *2]\n",
    "                train_y += [dataset_negative[i_n_class].label] * 2\n",
    "                \n",
    "                i_n_class+=1\n",
    "                if i_n_class >= len_n_class:\n",
    "                    i_n_class = 0\n",
    "                    i_n_img +=1\n",
    "                    if (i_n_img+1) *2 > len_n_imgs:\n",
    "                        i_n_img = 0\n",
    "#                     print('if i_n_class >= len_n_class i_n_class ',i_n_class)\n",
    "#                     print('if i_n_class >= len_n_class i_n_img ',i_n_img)\n",
    "            \n",
    "                create_negative_imgs +=2\n",
    "                if create_negative_imgs >= batch_negative:\n",
    "#                     print(\"create_negative_imgs ok \",create_negative_imgs)\n",
    "                    break\n",
    "                    \n",
    "                \n",
    "        create_positive_imgs = 0    \n",
    "        while create_positive_imgs < p_size:\n",
    "            for i in range(i_p_class,len_p_class):\n",
    "#                 print('for i in range(i_p_class     ',i_p_class)\n",
    "#                 print('for i in range(i_p_img  ',i_p_img)\n",
    "                \n",
    "                train_x += dataset_train_positive[i_p_class].imgs[i_p_img:(i_p_img +1)]\n",
    "                train_y += [dataset_train_positive[i_p_class].label]\n",
    "                \n",
    "                i_p_class+=1\n",
    "                if i_p_class >= len_p_class:\n",
    "                    i_p_class = 0\n",
    "                    i_p_img +=1\n",
    "                    if (i_p_img +1) > len_p_imgs:\n",
    "                        i_p_img = 0\n",
    "#                     print('if i_p_class >= len_p_class i_p_class ',i_p_class)\n",
    "#                     print('if i_p_class >= len_p_class i_p_img ',i_p_img)\n",
    "                \n",
    "                create_positive_imgs+=1\n",
    "                if create_positive_imgs >= p_size:\n",
    "#                     print(\"create_positive_imgs ok \",create_positive_imgs)\n",
    "                    break\n",
    "        \n",
    "        shuffindex_out = np.random.permutation(len(train_y))\n",
    "#         print(train_x[0].shape)\n",
    "        train_x = np.stack(train_x,axis = 0)\n",
    "#         print('after concat : ',train_x[0].shape)\n",
    "        train_x = train_x[shuffindex_out]\n",
    "        train_y = np.array(train_y)[shuffindex_out]\n",
    "        \n",
    "        yield train_x,train_y  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataaaaaaa = get_next_perfect(dataset_train_positive,dataset_negative,4,126)\n",
    "for x ,y in dataaaaaaa:\n",
    "    print(y)\n",
    "    print('x o shape ' ,x.shape,y.shape)\n",
    "    print(\"one batch is over\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getnext_test(dataset_test_positive,test_class_index):\n",
    "    \n",
    "    for data in dataset_test_positive:\n",
    "        x = np.stack(data.imgs,axis =0)\n",
    "        y = np.array([test_class_index.index(data.label)] * len(data.imgs))\n",
    "        yield x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataaaaaaa = getnext_test(dataset_test_positive,test_class_index)\n",
    "for x ,y in dataaaaaaa:\n",
    "    print(y)\n",
    "    print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imgs_show_norm(imgs,row,col):\n",
    "    fig,ax = plt.subplots(nrows=row,ncols=col,sharex=True,sharey=True)\n",
    "    ax = ax.flatten()\n",
    "    for i in range(row*col):\n",
    "        img = imgs[i]\n",
    "        min = np.min(img)\n",
    "#         print('min = ',min)\n",
    "        img = np.subtract(img,min) # 0->\n",
    "        max = np.max(img)\n",
    "#         print('max =',max)\n",
    "        img = np.divide(img,max)\n",
    "        \n",
    "        ax[i].imshow(img,cmap='Greys', interpolation='nearest')\n",
    "    \n",
    "    ax[0].set_xticks([])\n",
    "    ax[0].set_yticks([])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img_show_norm(img):\n",
    "    min_ = np.min(img)\n",
    "#     print('min = ',min_)\n",
    "    img = np.subtract(img,min_) # 0->\n",
    "    max_ = np.amax(a = img,keepdims=False)\n",
    "#     print('max =',max_)\n",
    "    img = np.divide(img,max_)  # 0->1\n",
    "#     print(img)\n",
    "    plt.figure(figsize=(1,1))\n",
    "    plt.imshow(img,cmap='Greys',interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img_show(img):\n",
    "    plt.figure(figsize=(1,1))\n",
    "    plt.imshow(img,cmap='Greys',interpolation='nearest')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imgs_show(imgs,row,col):\n",
    "    fig,ax = plt.subplots(nrows=row,ncols=col,sharex=True,sharey=True)\n",
    "    ax = ax.flatten()\n",
    "    for i in range(row*col):\n",
    "        img = imgs[i]\n",
    "        \n",
    "        ax[i].imshow(img,cmap='Greys', interpolation='nearest')\n",
    "    \n",
    "    ax[0].set_xticks([])\n",
    "    ax[0].set_yticks([])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn_index = [-1,1]\n",
    "def compute_index_logical_equal(inputs,indexs):\n",
    "    logic_result = (inputs==indexs[0])\n",
    "    for value in indexs:\n",
    "        logic_result = np.logical_or(inputs == value,logic_result)\n",
    "    return logic_result\n",
    "\n",
    "def compute_index_logical_not_equal(inputs,indexs):\n",
    "    logic_result = (inputs==indexs[0])\n",
    "    for value in indexs:\n",
    "        logic_result = np.logical_or(inputs == value,logic_result)\n",
    "    return np.logical_not(logic_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AssociateGlowGenerated(nn.Module):\n",
    "    def __init__(self, test_class_index, is_mean, K, class_number):\n",
    "        super(AssociateGlowGenerated, self).__init__()\n",
    "        self.glow = models.Glow(JsonConfig(\"hparams/omni_all_bg.json\"), test_class_index=test_class_index , is_mean=is_mean, K=K, y_classes=class_number)\n",
    "        self.class_number = class_number\n",
    "        self.eval_index = test_class_index\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.ones_tensor = torch.ones((1, 32, 32)).float().cuda()\n",
    "\n",
    "        self.glow_generate = models.Glow(JsonConfig(\"hparams/omni_all_bg.json\"), test_class_index=test_class_index,\n",
    "                                is_mean=is_mean, K=K, y_classes=class_number)\n",
    "\n",
    "    def restore_glow_params(self,state_dict):\n",
    "        self.glow.load_state_dict(state_dict)\n",
    "\n",
    "    def resoter_glow_g_params(self,state_dict):\n",
    "        self.glow_generate.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "    def forward(self, inputs=None, labels=None, y_onehot=None, eps_std=None):\n",
    "\n",
    "        x_shape = inputs.size()\n",
    "        y_shape = labels.size()\n",
    "        assert x_shape[0] == y_shape[0]\n",
    "        #         print(labels)\n",
    "        y_onehot = torch.FloatTensor(y_shape[0], self.class_number).cuda()  # if use gpu ,\n",
    "        y_onehot.zero_()\n",
    "        y_onehot.scatter_(1, labels.view(-1, 1), 1)\n",
    "        filter_g_img = None\n",
    "        #         print(y_onehot[0])\n",
    "\n",
    "        \n",
    "        #  generate image\n",
    "        if self.training:\n",
    "            with torch.no_grad():\n",
    "                # decode input\n",
    "                z, det = self.glow_generate(x=inputs, y_onehot=y_onehot, reverse=False)\n",
    "\n",
    "                if not isinstance(labels, torch.Tensor):\n",
    "                    labels = torch.from_numpy(labels)\n",
    "\n",
    "\n",
    "                # z algorithm\n",
    "                positive_index = compute_index_logical_equal(labels, self.eval_index)\n",
    "                negitive_index = compute_index_logical_not_equal(labels, self.eval_index)\n",
    "                #             print(\"positive_index:\", positive_index)\n",
    "                #             print(\"negitive_index:\", negitive_index)\n",
    "\n",
    "                z_negative = z[negitive_index]\n",
    "                assert len(z_negative) % 2 == 0\n",
    "                y_negative = labels[negitive_index]\n",
    "                #             print('y_negative = ', y_negative)\n",
    "                x_positive = z[positive_index]\n",
    "                y_positive = labels[positive_index]\n",
    "                #             print('y_positive = ', y_positive)\n",
    "\n",
    "                sorted_y, indices_y = torch.sort(y_negative)\n",
    "                z_negavite_sort = z_negative[indices_y]\n",
    "                #             print('sorted_y = ', sorted_y)\n",
    "                #             print('indices_y = ', indices_y)\n",
    "                #             print('labels[indices_y] = ', labels[indices_y])\n",
    "                #             print('y_negative[indices_y] = ', y_negative[indices_y])\n",
    "\n",
    "                # sample\n",
    "                z_size = z.size()\n",
    "                batch_g_z_size = len(y_negative) // 2\n",
    "                #             print('batch_g_size = ', batch_g_z_size)\n",
    "\n",
    "                g_z = torch.zeros([batch_g_z_size, z_size[1], z_size[2], z_size[3]]).cuda()  # require_grad = False\n",
    "                label_g_c = torch.zeros(batch_g_z_size).long().cuda()\n",
    "                #             print('self.g_z = ', self.g_z.size())\n",
    "                #             print('self.label_g_c = ', self.label_g_c.size())\n",
    "\n",
    "                i = 0\n",
    "\n",
    "                while i < batch_g_z_size:\n",
    "                    for index_p in range(len(x_positive)):\n",
    "                        g_z[i] = x_positive[index_p]\n",
    "\n",
    "                        p = 0.6  # np.random.uniform(0.45, 0.5)\n",
    "                        q = np.random.randint(0, 2)\n",
    "                        scale = nn_index[q] * p\n",
    "\n",
    "                        #                     start_index = np.random.randint(0,32)\n",
    "                        #                     # start_index = 0\n",
    "                        #                     end_index = start_index + 32\n",
    "                        slic_index = np.random.permutation(64)[:20]\n",
    "                        #                     print('scale = {},slic_index ={}'.format(scale,slic_index))\n",
    "                        #                     print('y_positive[index_p] = {},y_negative[2 * i] ={}, y_negative[2 * i + 1] = {}'.\n",
    "                        #                           format(y_positive[index_p],y_negative[indices_y][2 * i],y_negative[indices_y][2 * i + 1]))\n",
    "                        #                     g_z[i][start_index:end_index] =  g_z[i][start_index:end_index] + \\\n",
    "                        #                                                                  scale * ( z_negavite_sort[2 * i][start_index:end_index] -\n",
    "                        #                                                                                  z_negavite_sort[2 * i + 1][start_index:end_index])\n",
    "\n",
    "                        g_z[i][slic_index] = g_z[i][slic_index] + scale * (\n",
    "                                    z_negavite_sort[2 * i][slic_index] -\n",
    "                                    z_negavite_sort[2 * i + 1][slic_index])\n",
    "\n",
    "                        label_g_c[i] = y_positive[index_p]\n",
    "                        i += 1\n",
    "                        if i >= batch_g_z_size:\n",
    "                            break\n",
    "\n",
    "                #             print('label_g_c = ', label_g_c)\n",
    "                # shuff_g_index = np.random.permutation(batch_g_z_size)\n",
    "                # sg_z = .g_z[shuff_g_index]\n",
    "                # .label_g_c = .label_g_c[shuff_g_index]\n",
    "\n",
    "                # generate img\n",
    "\n",
    "                y_onehot_g = torch.FloatTensor(batch_g_z_size, self.class_number).cuda()  # if use gpu ,\n",
    "                y_onehot_g.zero_()\n",
    "                y_onehot_g.scatter_(1, label_g_c.view(-1, 1), 1)\n",
    "\n",
    "                g_img = self.glow_generate(z=g_z, y_onehot=y_onehot_g, eps_std=eps_std, reverse=True)\n",
    "                # print('g_img requires_grad = ', g_img.requires_grad)\n",
    "                g_img = torch.clamp(g_img, -1, 1)\n",
    "                g_img = g_img.detach()\n",
    "                #                 print('.g_img requires_grad = ', .g_img.requires_grad)\n",
    "\n",
    "                filter_index_list = []\n",
    "                # filter_g_label_list = []\n",
    "                # filter_g_oneshot_list = []\n",
    "\n",
    "                for i in range(len(g_img)):\n",
    "                    g_corr_label = (labels == label_g_c[i])\n",
    "                    #                     print('labels[g_corr_label ={}, label_g_c[i] = {}'.format(.label_g_c[i],labels[g_corr_label]))\n",
    "                    diff_g = self.criterion(g_img[i], inputs[g_corr_label][0]) / self.criterion(\n",
    "                        inputs[g_corr_label][0], self.ones_tensor)\n",
    "                    #                     print('diff_g = ',diff_g)\n",
    "\n",
    "                    if diff_g < 1:\n",
    "                        filter_index_list.append(i)\n",
    "\n",
    "                print('filter_index_ len  = ', len(filter_index_list))\n",
    "                filter_g_img = g_img[filter_index_list]\n",
    "                #                 print('filter_g_img shape = ', .filter_g_img.size())\n",
    "                filter_g_label = label_g_c[filter_index_list]\n",
    "                filter_g_oneshot = y_onehot_g[filter_index_list]\n",
    "\n",
    "                # shuff_g_index = np.random.permutation(len(.filter_g_label))\n",
    "                # .filter_g_img = .filter_g_img[shuff_g_index]\n",
    "                # .filter_g_label = .filter_g_label[shuff_g_index]\n",
    "                # .filter_g_oneshot = .filter_g_oneshot[shuff_g_index]\n",
    "\n",
    "                if len(filter_g_img) != 0:\n",
    "                    inputs = torch.cat((inputs, filter_g_img), 0)\n",
    "                    print('input_real shape = ', inputs.size())\n",
    "                    labels = torch.cat((labels, filter_g_label), 0)\n",
    "                    print('label_real shape = ', labels.size())\n",
    "                    y_onehot = torch.cat((y_onehot,filter_g_oneshot),0)\n",
    "                    print('onehot_real shape = ', y_onehot.size())\n",
    "\n",
    "                    shuff_g_index = np.random.permutation(len(inputs))\n",
    "                    inputs = inputs[shuff_g_index]\n",
    "                    labels = labels[shuff_g_index]\n",
    "                    y_onehot= y_onehot[shuff_g_index]\n",
    "\n",
    "                   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # classify\n",
    "        z, det = self.glow(x=inputs, y_onehot=y_onehot, reverse=False)\n",
    "        y_logits = self.glow.class_flow(z)\n",
    "        return z, det, y_logits ,labels,filter_g_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AssociateGlow(nn.Module):\n",
    "    def __init__(self, test_class_index, is_mean, K, class_number):\n",
    "        super(AssociateGlow, self).__init__()\n",
    "        self.glow = models.Glow(JsonConfig(\"hparams/omni_all_bg.json\"), test_class_index=test_class_index \\\n",
    "                                , is_mean=is_mean, K=K, y_classes=class_number)\n",
    "        self.class_number = class_number\n",
    "        self.eval_index = test_class_index\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.ones_tensor = torch.ones((1,32,32)).float().cuda()\n",
    "\n",
    "    def forward(self, inputs=None, labels=None, y_onehot=None, eps_std=None):\n",
    "\n",
    "        x_shape = inputs.size()\n",
    "        y_shape = labels.size()\n",
    "        assert x_shape[0] == y_shape[0]\n",
    "\n",
    "#         print(labels)\n",
    "        y_onehot = torch.FloatTensor(y_shape[0], self.class_number).cuda()  # if use gpu ,\n",
    "        y_onehot.zero_()\n",
    "        y_onehot.scatter_(1, labels.view(-1, 1), 1)\n",
    "#         print(y_onehot[0])\n",
    "\n",
    "        # decode z\n",
    "        z, det = self.glow(x=inputs, y_onehot=y_onehot, reverse=False)\n",
    "\n",
    "        if self.training:\n",
    "            if not isinstance(labels, torch.Tensor):\n",
    "                labels = torch.from_numpy(labels)\n",
    "\n",
    "            # z algo\n",
    "            positive_index = compute_index_logical_equal(labels, self.eval_index)\n",
    "            negitive_index = compute_index_logical_not_equal(labels, self.eval_index)\n",
    "#             print(\"positive_index:\", positive_index)\n",
    "#             print(\"negitive_index:\", negitive_index)\n",
    "\n",
    "            z_negative = z[negitive_index]\n",
    "            assert len(z_negative) % 2 == 0\n",
    "            y_negative = labels[negitive_index]\n",
    "#             print('y_negative = ', y_negative)\n",
    "            x_positive = z[positive_index]\n",
    "            y_positive = labels[positive_index]\n",
    "#             print('y_positive = ', y_positive)\n",
    "\n",
    "            sorted_y, indices_y = torch.sort(y_negative)\n",
    "            z_negavite_sort = z_negative[indices_y]\n",
    "#             print('sorted_y = ', sorted_y)\n",
    "#             print('indices_y = ', indices_y)\n",
    "#             print('labels[indices_y] = ', labels[indices_y])\n",
    "#             print('y_negative[indices_y] = ', y_negative[indices_y])\n",
    "\n",
    "\n",
    "            # sample\n",
    "            z_size = z.size()\n",
    "            batch_g_z_size = len(y_negative) // 2\n",
    "#             print('batch_g_size = ', batch_g_z_size)\n",
    "\n",
    "            self.g_z = torch.zeros( [batch_g_z_size, z_size[1], z_size[2], z_size[3]]).cuda()  # require_grad = False\n",
    "            self.label_g_c = torch.zeros(batch_g_z_size).long().cuda()\n",
    "#             print('self.g_z = ', self.g_z.size())\n",
    "#             print('self.label_g_c = ', self.label_g_c.size())\n",
    "\n",
    "            i = 0\n",
    "            \n",
    "\n",
    "            while i < batch_g_z_size:\n",
    "                for index_p in range(len(x_positive)):\n",
    "                    self.g_z[i] = x_positive[index_p]\n",
    "                    \n",
    "                    p = 0.6 # np.random.uniform(0.45, 0.5)\n",
    "                    q = np.random.randint(0, 2)\n",
    "                    scale = nn_index[q] * p\n",
    "\n",
    "#                     start_index = np.random.randint(0,32)\n",
    "#                     # start_index = 0\n",
    "#                     end_index = start_index + 32\n",
    "                    slic_index = np.random.permutation(64)[:20]\n",
    "#                     print('scale = {},slic_index ={}'.format(scale,slic_index))\n",
    "#                     print('y_positive[index_p] = {},y_negative[2 * i] ={}, y_negative[2 * i + 1] = {}'.\n",
    "#                           format(y_positive[index_p],y_negative[indices_y][2 * i],y_negative[indices_y][2 * i + 1]))\n",
    "#                     self.g_z[i][start_index:end_index] =  self.g_z[i][start_index:end_index] + \\\n",
    "#                                                                  scale * ( z_negavite_sort[2 * i][start_index:end_index] -\n",
    "#                                                                                  z_negavite_sort[2 * i + 1][start_index:end_index])\n",
    "                        \n",
    "                    self.g_z[i][slic_index] =  self.g_z[i][slic_index] + scale * ( z_negavite_sort[2 * i][slic_index] - \n",
    "                                                                                  z_negavite_sort[2 * i + 1][slic_index])\n",
    "                        \n",
    "                    self.label_g_c[i] = y_positive[index_p]\n",
    "                    i += 1\n",
    "                    if i >= batch_g_z_size:\n",
    "                        break\n",
    "\n",
    "#             print('self.label_g_c = ', self.label_g_c)\n",
    "            # shuff_g_index = np.random.permutation(batch_g_z_size)\n",
    "            # self.g_z = self.g_z[shuff_g_index]\n",
    "            # self.label_g_c = self.label_g_c[shuff_g_index]\n",
    "\n",
    "            # generate img\n",
    "\n",
    "            self.y_onehot_g = torch.FloatTensor(batch_g_z_size, self.class_number).cuda()  # if use gpu ,\n",
    "            self.y_onehot_g.zero_()\n",
    "            self.y_onehot_g.scatter_(1, self.label_g_c.view(-1, 1), 1)\n",
    "\n",
    "            with torch.no_grad():  # generate net grad ------------------- 需要更新的 因为x_c 一直在更新\n",
    "                self.g_img = self.glow(z=self.g_z, y_onehot=self.y_onehot_g, eps_std=eps_std, reverse=True)\n",
    "                # print('self.g_img requires_grad = ', self.g_img.requires_grad)\n",
    "                self.g_img = torch.clamp(self.g_img, -1, 1)\n",
    "                self.g_img = self.g_img.detach()\n",
    "#                 print('self.g_img requires_grad = ', self.g_img.requires_grad)\n",
    "\n",
    "                filter_index_list = []\n",
    "                # filter_g_label_list = []\n",
    "                # filter_g_oneshot_list = []\n",
    "\n",
    "                for i in range(len(self.g_img)):\n",
    "                    g_corr_label = (labels == self.label_g_c[i])\n",
    "#                     print('labels[g_corr_label ={}, label_g_c[i] = {}'.format(self.label_g_c[i],labels[g_corr_label]))\n",
    "                    diff_g = self.criterion (self.g_img[i] , inputs[g_corr_label][0]) / self.criterion (inputs[g_corr_label][0],self.ones_tensor)\n",
    "#                     print('diff_g = ',diff_g)\n",
    "\n",
    "                    if diff_g < 1:\n",
    "                        filter_index_list.append(i)\n",
    "\n",
    "                print('filter_index_ len  = ', len(filter_index_list))\n",
    "                self.filter_g_img = self.g_img[filter_index_list]\n",
    "#                 print('filter_g_img shape = ', self.filter_g_img.size())\n",
    "                self.filter_g_label = self.label_g_c[filter_index_list]\n",
    "                self.filter_g_oneshot =self.y_onehot_g[filter_index_list]\n",
    "        \n",
    "                shuff_g_index = np.random.permutation(len(self.filter_g_label))\n",
    "                self.filter_g_img = self.filter_g_img[shuff_g_index]\n",
    "                self.filter_g_label =self.filter_g_label[shuff_g_index]\n",
    "                self.filter_g_oneshot = self.filter_g_oneshot[shuff_g_index]\n",
    "\n",
    "#                 print('filter_g_label shape = ', self.filter_g_label.size())\n",
    "#                 print('filter_g_label  = ', self.filter_g_label)\n",
    "#                 print('filter_g_oneshot shape = ', self.filter_g_oneshot.size())\n",
    "\n",
    "                # g_ = torch.norm(torch.norm(torch.norm(self.g_img, 2, 1), 2, 1), 2, 1) ** 2\n",
    "\n",
    "\n",
    "        if self.training and len(self.filter_g_img) != 0 :\n",
    "            # classify\n",
    "            z_g, det_g = self.glow(x=self.filter_g_img, y_onehot=self.filter_g_oneshot, reverse=False)\n",
    "#             print('det_g requires_grad = ', z_g.requires_grad)\n",
    "\n",
    "        y_logits = self.glow.class_flow(z)\n",
    "            \n",
    "        if self.training and len(self.filter_g_img) != 0 :\n",
    "            y_logits_g = self.glow.class_flow(z_g)\n",
    "#             print('y_logits_g size  = ', y_logits_g.size())\n",
    "            return det, det_g, y_logits, y_logits_g, self.filter_g_label\n",
    "        if self.training:\n",
    "            return det,None,y_logits,None,self.filter_g_label\n",
    "        return det,  y_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nb_digits = class_total_num\n",
    "# net_auto = AssociateGlow(test_class_index,is_mean=True,K= 8,class_number=class_total_num)\n",
    "net_auto = AssociateGlowGenerated(test_class_index,is_mean=True,K= 8,class_number=class_total_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#     print(k)\n",
    "pt1 = torch.load('model_glow_ominst_all_bg_8k_20_way_778.pt')\n",
    "pt2 = torch.load('model_glow_ominst_all_bg_8k_20_way_778.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for k ,v in pt_asso.items():\n",
    "#     print(k)\n",
    "#     print(v)\n",
    "# for k ,v in pm.items():\n",
    "\n",
    "\n",
    "net_auto.restore_glow_params(pt1)\n",
    "net_auto.resoter_glow_g_params(pt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(pt1.has_key)\n",
    "print(pt2.has_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "pt_old = torch.load('model_glow_ominst_all_bg_8k_20_way_778.pt')\n",
    "# pm = net_auto.state_dict()\n",
    "pt_asso = collections.OrderedDict()\n",
    "for k ,v in pt_old.items():\n",
    "#     print(k)\n",
    "#     print('glow.'+k)\n",
    "#     print(type(k))\n",
    "    pt_asso['glow.'+k] = v\n",
    "#     print(v)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "a = net_auto.load_state_dict(pt_asso)\n",
    "# for param in net_auto.parameters():\n",
    "#     print(param.name)\n",
    "a = net_auto.parameters().next()\n",
    "print(a)\n",
    "print(pt_old['flow.layers.1.actnorm.bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# net_auto.load_state_dict(pt_asso)\n",
    "# net_auto.load_state_dict(torch.load('model_assoiatet_glow_ominst_all_bg_200.pt'))\n",
    "# net_auto.load_state_dict(torch.load('model_assoiatet_glow_ominst_all_bg_77.pt'))\n",
    "# net_auto.load_state_dict(torch.load('model_glow_ominst_no_split2d_4k_4316.pt'))\n",
    "# net_auto.load_state_dict(torch.load('model_glow_ominst_no_split2d_8k_9000.pt'))\n",
    "use_cuda = torch.cuda.is_available()\n",
    "# torch.manual_seed(666)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "net_auto.to(device)\n",
    "net_auto.float()\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net_auto.parameters(),lr=0.0001,weight_decay=1e-5) # decoder don't weight_decay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#X_train_nor\n",
    "# batch_size = 512\n",
    "net_auto.train()\n",
    "for epoch in range(200):\n",
    "    #train:\n",
    "    \n",
    "    datas =  get_next_perfect(dataset_train_positive,dataset_negative,16,200)\n",
    "#     datas = getnext(dataset_train_positive,dataset_negative)\n",
    "    \n",
    "    trainloss_g = 0\n",
    "    trainloss_c = 0\n",
    "    \n",
    "    for x,y in datas:\n",
    "        inputs ,lables = torch.from_numpy(x).float().to(device),\\\n",
    "            torch.from_numpy(y).long().to(device)\n",
    "#         print(torch.sum(lables)) # = 1167\n",
    "        \n",
    "#         y_onehot = torch.FloatTensor(batch_size, nb_digits).to(device)\n",
    "#         y_onehot.zero_()\n",
    "#         y_onehot.scatter_(1, lables.view(-1,1), 1)\n",
    "#         print('y_onehot:', y_onehot)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "#         det,det_g, y_logits,y_logit_g,label_g_c = net_auto(inputs=inputs, labels = lables ,y_onehot=None,eps_std=None)\n",
    "        z, det, y_logits ,labels_g,filter_g_img = net_auto(inputs=inputs, labels = lables ,y_onehot=None,eps_std=None)\n",
    "#         print(z.size())\n",
    "#         print(det)\n",
    "        \n",
    "        loss_g1 = models.Glow.loss_generative(det)\n",
    "#         loss_g2 = models.Glow.loss_generative(det_g)\n",
    "    \n",
    "        loss_c1 = models.Glow.loss_class(y_logits,labels_g)\n",
    "#         loss_c2 = models.Glow.loss_class(y_logit_g,label_g_c)\n",
    "        \n",
    "#         print('loss_g1 = ',loss_g1.item())\n",
    "#         print('loss_g2 = ',loss_g2.item())\n",
    "#         print('loss_c1 =  ',loss_c1.item())\n",
    "#         print('loss_c2 =  ',loss_c2.item())\n",
    "        print('%d  loss_g1: %.4f,loss_c1: %.4f ' % (epoch , loss_g1.item(),loss_c1.item()))\n",
    "#         print('label_g_c =  ',label_g_c[:25])\n",
    "#         if epoch > 20:\n",
    "#         if filter_g_img is not None and len(filter_g_img) > 25 and epoch > 20:\n",
    "#             imgs_show(np.squeeze(filter_g_img),5,5)\n",
    "        \n",
    "        loss = loss_g1  + loss_c1 * 0.2 \n",
    "#         loss = loss_g1 + + loss_c1 * 0.2\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_value_(net_auto.parameters(), 5)\n",
    "        torch.nn.utils.clip_grad_norm_(net_auto.parameters(), 100)\n",
    "        \n",
    "        \n",
    "#         trainloss_g += (loss_g1.item()+ loss_g2.item())\n",
    "#         trainloss_c += (loss_c1.item() + loss_c2.item())\n",
    "#         print(\"net_auto.conv_d1 grad:\",net_auto.conv_d1.weight.grad)\n",
    "        \n",
    "#         print(\"after net_auto.conv_1 grad:\",net_auto.conv1.weight.grad)\n",
    "        optimizer.step()\n",
    "    \n",
    "        \n",
    "        \n",
    "    print('%d  gloss: %.3f, class loss:%.3f' % (epoch ,  trainloss_g,trainloss_c))\n",
    "    \n",
    "    if epoch % 10 == 0 and epoch >0:\n",
    "        torch.save(net_auto.state_dict(),'model_assoiatet_glow_ominst_all_bg_ge_nograd_'+str(epoch)+'.pt')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# net_auto.load_state_dict(torch.load('model_assoiatet_glow_ominst_all_bg_ge_nograd_10.pt'))\n",
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(666)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "net_auto.to(device)\n",
    "net_auto.float()\n",
    "net_auto.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "test_datas = getnext_test(dataset_test_positive,test_class_index)\n",
    "for x ,y in test_datas:\n",
    "        inputs, labels = Variable(torch.from_numpy(x).float()).cuda(), Variable(torch.from_numpy(y).long()).cuda()\n",
    "        z, det, y_logits ,labels_g,filter_g_img = net_auto(inputs=inputs, labels = labels ,y_onehot=None,eps_std=None)\n",
    "        \n",
    "#         _,classify = net_auto(inputs)\n",
    "        test_loss += models.Glow.loss_class(y_logits,labels)  # sum up batch loss\n",
    "#         print(test_loss)\n",
    "        pred = y_logits.max(1,keepdim=True)[1]\n",
    "#         print(pred)\n",
    "        \n",
    "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "#         print(correct)\n",
    "print(correct)\n",
    "print(correct * 1.0 / (19 * 20))\n",
    "print(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# net_auto.load_state_dict(torch.load('model_glow_ominst2000.pt'))\n",
    "\n",
    "\n",
    "# use_cuda = torch.cuda.is_available()\n",
    "# torch.manual_seed(666)\n",
    "# device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "# net_auto.to(device)\n",
    "# net_auto.float()\n",
    "# net_auto.load_state_dict(torch.load('model_glow_ominst_no_split2d_no_z_mean_no_add_normal1223.pt'))\n",
    "# torch.cuda.empty_cache()\n",
    "# net_auto.load_state_dict(torch.load('model_assoiatet_glow_ominst_all_bg_900.pt'))\n",
    "net_auto.train()\n",
    "torch.save(net_auto.state_dict(),'model_assoiatet_glow_ominst_all_bg_ge_nograd_50.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "posi = np.concatenate(( np.array(dataset_train_positive[3].imgs[1:2])  ,  np.array(dataset_negative[112].imgs[1:3])   ))\n",
    "labl =  np.array([dataset_train_positive[3].label, dataset_negative[12].label,dataset_negative[112].label])\n",
    "\n",
    "inputs ,lables = torch.from_numpy(posi).float().to(device),\\\n",
    "            torch.from_numpy(labl).long().to(device)\n",
    "        \n",
    "y_onehot = torch.FloatTensor(3, nb_digits).to(device)\n",
    "y_onehot.zero_()\n",
    "y_onehot.scatter_(1, lables.view(-1,1), 1)\n",
    "# print('y_onehot:', y_onehot)\n",
    "z, det, y_logits = net_auto(x=inputs, y_onehot=y_onehot)\n",
    "\n",
    "\n",
    "print('z.size() ' ,z.size())\n",
    "print('y_logits.size() ' ,y_logits.size())\n",
    "print(y_logits[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "obj = z[0]\n",
    "# print(obj[0])\n",
    "obj = z[0] \n",
    "\n",
    "print(torch.sum(torch.abs(z[2]),dim =(1,2)))\n",
    "print(torch.sum(torch.abs(z[1]),dim =(1,2)))\n",
    "\n",
    "print(torch.sum(torch.abs(z[0]),dim =(1,2)))\n",
    "obj[:][:] = z[0][:] + 0.5 * (z[1][:] - z[2][:])\n",
    "\n",
    "print(obj.size())\n",
    "obj = obj.view(-1,*obj.size())\n",
    "print(obj.size())\n",
    "obj_oneshot = y_onehot[0].view(-1,class_total_num)\n",
    "print(obj_oneshot.size())\n",
    "# print(obj_oneshot)\n",
    "# print(obj[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# z = z.detach().cpu().numpy()\n",
    "# print(z.size())\n",
    "# print(z[0][0][0])\n",
    "x_ = net_auto(z = obj,y_onehot = obj_oneshot,eps_std = None ,reverse=True)\n",
    "\n",
    "x_ = torch.clamp(x_,-1,1)\n",
    "print(x_.size())\n",
    "print(torch.sum(torch.abs(x_ - inputs[0])))\n",
    "print(x_[0][0][0])\n",
    "print(inputs[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_show(np.squeeze(x_.data))\n",
    "img_show(np.squeeze(inputs.data[0]))\n",
    "imgs_show(np.squeeze(inputs.data),1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
